{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import tensorflow as tf\n",
    "from sklearn import preprocessing\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "trainSet = pd.read_excel('trainSetFrom_data_accident_final_17.10.17_17.10.24.xlsx')\n",
    "testSet = pd.read_excel('testSetFrom_data_accident_final_17.10.17_17.10.24.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['index', '所辖乡镇', '行政区划', '事故发生时间', '星期', '路号', '受伤人数', '当事人总数',\n",
       "       '抢救死亡人数Q', '机动车数量', '死亡人数', '直接财产损失', '米数', '轻伤人数', '重伤人数', '非机动车数量',\n",
       "       '行人数量', '事故形态', '事故类型', '单车事故', '是否简易程序', '是否路外事故', '车辆间事故.1', '逃逸事故侦破',\n",
       "       '事故认定原因', '事故认定原因分类小类', 'index.1'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainSet.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#将trainset与testset数字化\n",
    "trainSet.drop(['index','index.1'],axis=1,inplace=True)\n",
    "testSet.drop(['index','index.1'],axis=1,inplace=True)\n",
    "trainSet.drop(['星期'],axis=1,inplace=True)\n",
    "testSet.drop(['星期'],axis=1,inplace=True)\n",
    "\n",
    "\n",
    "\n",
    "columnsToNum = list(trainSet.columns)\n",
    "columnsToNum.remove('车辆间事故.1')\n",
    "trainSet_toNum = pd.DataFrame()\n",
    "for i in columnsToNum:\n",
    "    trainSet_toNum[i] = preprocessing.LabelEncoder().fit_transform(trainSet[i])\n",
    "trainSet_toNum.insert(value=list(trainSet['车辆间事故.1']),column='车辆间事故.1',loc=21)\n",
    "\n",
    "columnsToNum = list(testSet.columns)\n",
    "columnsToNum.remove('车辆间事故.1')\n",
    "testSet_toNum = pd.DataFrame()\n",
    "for i in columnsToNum:\n",
    "    testSet_toNum[i] = preprocessing.LabelEncoder().fit_transform(testSet[i])\n",
    "testSet_toNum.insert(value=list(testSet['车辆间事故.1']),column='车辆间事故.1',loc=21)\n",
    "\n",
    "del trainSet,testSet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#统一训练集、测试集格式\n",
    "x_train =np.array(trainSet_toNum.drop(['事故类型'],axis=1)) \n",
    "y_train = np.array(trainSet_toNum['事故类型'])\n",
    "y = np.zeros((len(y_train),4))\n",
    "for i in range(len(y_train)):\n",
    "    y[i][y_train[i]] = 1\n",
    "y_train = np.mat(y)\n",
    "x_train = np.mat(x_train)\n",
    "y_train = np.mat(y_train)\n",
    "\n",
    "\n",
    "x_test =np.array(testSet_toNum.drop(['事故类型'],axis=1)) \n",
    "y_test = np.array(testSet_toNum['事故类型'])\n",
    "y = np.zeros((len(y_test),4))\n",
    "for i in range(len(y_test)):\n",
    "    y[i][y_test[i]] = 1\n",
    "y_test = np.mat(y)\n",
    "x_test = np.mat(x_test)\n",
    "y_test = np.mat(y_test)\n",
    "\n",
    "\n",
    "del y,trainSet_toNum,testSet_toNum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "训练集维度：(113344, 23)\n",
      "训练集标签维度：(113344, 4)\n",
      "测试集维度：(20001, 23)\n",
      "测试集标签维度：(20001, 4)\n"
     ]
    }
   ],
   "source": [
    "print('训练集维度：%s'%str(x_train.shape))\n",
    "print('训练集标签维度：%s'%str(y_train.shape))\n",
    "print('测试集维度：%s'%str(x_test.shape))\n",
    "print('测试集标签维度：%s'%str(y_test.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def add_layer(inputs, in_size, out_size,n_layer, activation_function=None,):\n",
    "    # add one more layer and return the output of this layer\n",
    "    layer_name = 'layer%s'%n_layer\n",
    "    Weights = tf.Variable(tf.random_normal([in_size, out_size]),name='W'+str(n_layer))\n",
    "    biases = tf.Variable(tf.zeros([1, out_size]) + 0.1,name='b'+str(n_layer))\n",
    "    Wx_plus_b = tf.matmul(inputs, Weights) + biases\n",
    "\n",
    "    if activation_function is None:\n",
    "        outputs = Wx_plus_b\n",
    "    else:\n",
    "        outputs = activation_function(Wx_plus_b,)\n",
    "    return outputs\n",
    "     \n",
    "def compute_accuracy(v_xs, v_ys):\n",
    "    global prediction\n",
    "    y_pre = sess.run(prediction, feed_dict={xs: v_xs})\n",
    "    correct_prediction = tf.equal(tf.argmax(y_pre,1), tf.argmax(v_ys,1))\n",
    "    accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n",
    "    result = sess.run(accuracy, feed_dict={xs: v_xs, ys: v_ys})\n",
    "    return result\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "xs = tf.placeholder(tf.float32, [None, x_train.shape[1]],name='x_input') # \n",
    "ys = tf.placeholder(tf.float32, [None, y_train.shape[1]],name='y_input')\n",
    "\n",
    "l1 = add_layer(xs, x_train.shape[1], 18,n_layer=1,  activation_function=tf.nn.tanh)\n",
    "l2 = add_layer(l1, 18, 10,n_layer=2,  activation_function=tf.nn.tanh)\n",
    "prediction = add_layer(l2,10,y_train.shape[1],n_layer=3,activation_function=tf.nn.softmax)\n",
    "# the error between prediction and real data\n",
    "loss = tf.reduce_mean(-tf.reduce_sum(ys * tf.log(prediction), reduction_indices=[1]))       # loss\n",
    "train_step = tf.train.AdamOptimizer(0.2).minimize(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.986237\n",
      "0.986237\n",
      "0.986237\n",
      "0.986237\n",
      "0.986237\n",
      "0.986237\n",
      "0.986237\n",
      "0.986237\n",
      "0.986237\n",
      "0.986237\n"
     ]
    }
   ],
   "source": [
    "sess = tf.Session()\n",
    "init = tf.global_variables_initializer()\n",
    "sess.run(init)\n",
    "\n",
    "for i in range(10):\n",
    "    sess.run(train_step, feed_dict={xs: x_train, ys: y_train})\n",
    "#     if i % 10 == 0:\n",
    "    result = sess.run(train_step, feed_dict={xs: x_train, ys: y_train})\n",
    "    print(compute_accuracy(x_train, y_train))\n",
    "#         writer.add_summary(result,i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.986237\n",
      "0.986251\n"
     ]
    }
   ],
   "source": [
    "print(compute_accuracy(x_train, y_train))\n",
    "print(compute_accuracy(x_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "forest = RandomForestClassifier(n_estimators=10000,random_state=0,n_jobs=-1)\n",
    "forest.fit(x_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ True  True  True]\n",
      " [ True  True  True]\n",
      " [ True  True  True]]\n",
      "1.0\n"
     ]
    }
   ],
   "source": [
    "corr_pre_train = np.equal(np.argmax(forest.predict(x_train),axis=1),\\\n",
    "                    np.argmax(y_train[0:3],axis=1,).reshape( (1,len(np.argmax(y_train,axis=1,))) )\\\n",
    "                   )\n",
    "acc_train = np.mean(corr_pre_train)\n",
    "\n",
    "corr_pre_test = np.equal(np.argmax(forest.predict(x_test),axis=1),\\\n",
    "                    np.argmax(y_test[0:3],axis=1,).reshape( (1,len(np.argmax(y_test,axis=1,))) )\\\n",
    "                   )\n",
    "acc_test = np.mean(corr_pre_test)\n",
    "\n",
    "print('训练集准确率：%s'%acc_train)\n",
    "print('测试集准确率：%s'%acc_test)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
