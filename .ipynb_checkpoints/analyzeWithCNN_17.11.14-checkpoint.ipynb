{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\ProgramFiles\\Anaconda3\\lib\\site-packages\\sklearn\\cross_validation.py:44: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n",
      "D:\\ProgramFiles\\Anaconda3\\lib\\site-packages\\sklearn\\grid_search.py:43: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. This module will be removed in 0.20.\n",
      "  DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pandas.tseries.holiday import USFederalHolidayCalendar as calendar\n",
    "\n",
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "from pandas.tools.plotting import parallel_coordinates\n",
    "\n",
    "import matplotlib as mpl\n",
    "from matplotlib.font_manager import FontProperties\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.pylab import rcParams\n",
    "import seaborn as sns\n",
    "sns.set_style(\"darkgrid\",{\"font.sans-serif\":['simhei', 'Arial']})\n",
    "# rcParams['figure.figsize'] = 12, 4\n",
    "from scipy import stats\n",
    "import math\n",
    "\n",
    "\n",
    "import xgboost as xgb\n",
    "from xgboost.sklearn import XGBClassifier\n",
    "from sklearn import cross_validation, metrics   #Additional scklearn functions\n",
    "from sklearn.grid_search import GridSearchCV   #Perforing grid search\n",
    "\n",
    "from sklearn import preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "196169\n",
      "3052\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\ProgramFiles\\Anaconda3\\lib\\site-packages\\ipykernel\\__main__.py:7: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "D:\\ProgramFiles\\Anaconda3\\lib\\site-packages\\pandas\\core\\frame.py:2842: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  downcast=downcast, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "中央隔离设施: 0.240349599417  是否节假日: 0.0  是否白天: 0.0  是否双道: 0.28987618354  \n",
      "路宽: 0.28987618354  事故地点: 0.0  事故多发点段: 0.0  事故类型: 0.0  \n",
      "交通信号方式（控制）: 0.0  交通标志标线完善: 0.0  公路行政等级: 0.402039329934  公里数: 0.0  \n",
      "其他交通安全设施不全: 0.0  在道路横断面位置: 0.0  地形: 0.0  天气: 0.0  \n",
      "所辖乡镇: 0.0  星期: 0.0  是否运载危险物品: 0.0  照明条件: 0.0  \n",
      "能见度: 0.0  行政区划: 0.0  路侧防护设施类型: 0.0  路口路段类型: 0.0  \n",
      "路号: 0.0  路表情况: 0.0  路面状况: 0.0  路面结构: 0.0  \n",
      "道路安全属性: 0.0  道路安全隐患督办等级: 0.0  道路物理隔离: 0.0  道路类型: 0.0  \n",
      "道路线型: 0.0  长下坡路段: 0.0  774\n"
     ]
    }
   ],
   "source": [
    "data = pd.read_excel('data_accidentForPapaer_17.11.13.xlsx')\n",
    "data = data[data['路面附着系数'].isnull()]\n",
    "print(len(data))\n",
    "data_roadGrade_withoutJianyi = data[~data['事故类型'].isin(['简易程序事故'])]\n",
    "print(len(data_roadGrade_withoutJianyi))\n",
    "\n",
    "data_roadGrade_withoutJianyi.drop(['路面附着系数'],axis=1,inplace=True)\n",
    "data_roadGrade_withoutJianyi \\\n",
    "                        = data_roadGrade_withoutJianyi[data_roadGrade_withoutJianyi['是否节假日'].notnull()\\\n",
    "                        &data_roadGrade_withoutJianyi['事故多发点段'].notnull()\\\n",
    "                        &data_roadGrade_withoutJianyi['交通信号方式（控制）'].notnull()\\\n",
    "                        &data_roadGrade_withoutJianyi['公里数'].notnull()\\\n",
    "                        &data_roadGrade_withoutJianyi['其他交通安全设施不全'].notnull()\\\n",
    "                        &data_roadGrade_withoutJianyi['在道路横断面位置'].notnull()\\\n",
    "                        &data_roadGrade_withoutJianyi['地形'].notnull()\\\n",
    "                        &data_roadGrade_withoutJianyi['所辖乡镇'].notnull()\\\n",
    "                        &data_roadGrade_withoutJianyi['照明条件'].notnull()\\\n",
    "                        &data_roadGrade_withoutJianyi['能见度'].notnull()\\\n",
    "                        &data_roadGrade_withoutJianyi['路侧防护设施类型'].notnull()\\\n",
    "                        &data_roadGrade_withoutJianyi['路口路段类型'].notnull()\\\n",
    "                        &data_roadGrade_withoutJianyi['路表情况'].notnull()\\\n",
    "                        &data_roadGrade_withoutJianyi['路面状况'].notnull()\\\n",
    "                        &data_roadGrade_withoutJianyi['路面结构'].notnull()\\\n",
    "                        &data_roadGrade_withoutJianyi['道路安全属性'].notnull()\\\n",
    "                        &data_roadGrade_withoutJianyi['道路安全隐患督办等级'].notnull()\\\n",
    "                        &data_roadGrade_withoutJianyi['道路物理隔离'].notnull()\\\n",
    "                        &data_roadGrade_withoutJianyi['道路类型'].notnull()\\\n",
    "                        &data_roadGrade_withoutJianyi['道路线型'].notnull()]\n",
    "\n",
    "#整合路宽\n",
    "data_way = data_roadGrade_withoutJianyi[['单向路宽','双向路宽']]\n",
    "data_way.columns=['oneWay','twoWay']\n",
    "\n",
    "#填充空值为-1\n",
    "data_way.fillna(-1,inplace=True)\n",
    "\n",
    "def isTwowayRoad(row,oneWay,twoWay):\n",
    "    if row[oneWay] == -1 and row[twoWay] == -1:\n",
    "        return np.nan\n",
    "    elif row[oneWay] == -1:\n",
    "        return '是'\n",
    "    elif  row[twoWay] == -1:\n",
    "        return  '否'\n",
    "\n",
    "def getRoadWidth(row,oneWay,twoWay):\n",
    "    if row[oneWay] == -1 and row[twoWay] == -1:\n",
    "        return np.nan\n",
    "    elif row[oneWay] == -1:\n",
    "        return row[twoWay]\n",
    "    elif  row[twoWay] == -1:\n",
    "        return  row[oneWay]\n",
    "\n",
    "data_isTwoWay = pd.DataFrame(data_way.apply(isTwowayRoad, axis=1, oneWay='oneWay', twoWay='twoWay'),\\\n",
    "                             columns=['isTwoWay'])\n",
    "data_roadWidth = pd.DataFrame(data_way.apply(getRoadWidth, axis=1, oneWay='oneWay', twoWay='twoWay'),\\\n",
    "                             columns=['roadWidth'])\n",
    "\n",
    "data_roadGrade_withoutJianyi.insert(value=data_isTwoWay,column='是否双道',loc=3)\n",
    "data_roadGrade_withoutJianyi.insert(value=data_roadWidth,column='路宽',loc=4)\n",
    "\n",
    "# pd.DataFrame(data_attach_notnull[(data_attach_notnull['路宽']==-1)])[['是否双道','路宽','单向路宽','双向路宽']]\n",
    "data_roadGrade_withoutJianyi.drop(['单向路宽','双向路宽'],axis=1,inplace=True)\n",
    "del data_way,data_isTwoWay,data_roadWidth\n",
    "\n",
    "nan_columns = {}\n",
    "length_data = len(data_roadGrade_withoutJianyi)\n",
    "for i in range(len(data_roadGrade_withoutJianyi.columns)): \n",
    "    odds = sum(data_roadGrade_withoutJianyi[data_roadGrade_withoutJianyi.columns[i]].isnull())/length_data\n",
    "    nan_columns[data_roadGrade_withoutJianyi.columns[i]] = odds\n",
    "\n",
    "j = 0\n",
    "for i in nan_columns:\n",
    "    print(i+': '+str(nan_columns[i]),end='  ')\n",
    "    j+=1\n",
    "    if j==4:\n",
    "        j=0\n",
    "        print()\n",
    "        \n",
    "data_roadGrade_withoutJianyi = data_roadGrade_withoutJianyi[data_roadGrade_withoutJianyi['是否双道'].notnull()\\\n",
    "                                                        &data_roadGrade_withoutJianyi['中央隔离设施'].notnull()]\n",
    "print(len(data_roadGrade_withoutJianyi))\n",
    "data_roadGrade_withoutJianyi.drop(['公路行政等级'],axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "中央隔离设施: 0.0  是否节假日: 0.0  是否白天: 0.0  是否双道: 0.0  \n",
      "路宽: 0.0  事故地点: 0.0  事故多发点段: 0.0  事故类型: 0.0  \n",
      "交通信号方式（控制）: 0.0  交通标志标线完善: 0.0  公里数: 0.0  其他交通安全设施不全: 0.0  \n",
      "在道路横断面位置: 0.0  地形: 0.0  天气: 0.0  所辖乡镇: 0.0  \n",
      "星期: 0.0  是否运载危险物品: 0.0  照明条件: 0.0  能见度: 0.0  \n",
      "行政区划: 0.0  路侧防护设施类型: 0.0  路口路段类型: 0.0  路号: 0.0  \n",
      "路表情况: 0.0  路面状况: 0.0  路面结构: 0.0  道路安全属性: 0.0  \n",
      "道路安全隐患督办等级: 0.0  道路物理隔离: 0.0  道路类型: 0.0  道路线型: 0.0  \n",
      "长下坡路段: 0.0  index: 0.0  774\n"
     ]
    }
   ],
   "source": [
    "nan_columns = {}\n",
    "length_data = len(data_roadGrade_withoutJianyi)\n",
    "for i in range(len(data_roadGrade_withoutJianyi.columns)): \n",
    "    odds = sum(data_roadGrade_withoutJianyi[data_roadGrade_withoutJianyi.columns[i]].isnull())/length_data\n",
    "    nan_columns[data_roadGrade_withoutJianyi.columns[i]] = odds\n",
    "j = 0\n",
    "for i in nan_columns:\n",
    "    print(i+': '+str(nan_columns[i]),end='  ')\n",
    "    j+=1\n",
    "    if j==4:\n",
    "        j=0\n",
    "        print()\n",
    "        \n",
    "print(len(data_roadGrade_withoutJianyi))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 获取CNN训练集"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 获取某路号出现最多的道路相关属性"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'事故多发点段': 2.0, '交通信号方式（控制）': 45, '交通标志标线完善': '否', '其他交通安全设施不全': '否', '路侧防护设施类型': '无防护', '路口路段类型': '普通路段', '路面状况': '路面完好', '路面结构': '沥青', '道路安全属性': '正常路段', '道路安全隐患督办等级': 4.0, '道路物理隔离': '中心隔离', '道路类型': '高速', '道路线型': '平直', '长下坡路段': '否'}\n"
     ]
    }
   ],
   "source": [
    "# len(data_roadGrade_withoutJianyi.groupby(['路号']))\n",
    "info = {}\n",
    "for name,group in data_gbRoadNo:\n",
    "        for i in group.columns:\n",
    "            if i in roadColumns:\n",
    "                info[i] = group[i].value_counts().index[0]    \n",
    "        break\n",
    "print(info)\n",
    "# 事故多发点段,交通信号方式,交通标志标线完善,其他交通安全设施不全,路侧防护设施类型,路口路段类型,路面状况,路面结构,\n",
    "# 道路安全属性,道路安全隐患督办等级,道路物理隔离,道路类型,道路线型,长下坡路段"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "data_roadGrade_withoutJianyi['index']  = range(len(data_roadGrade_withoutJianyi))\n",
    "data_roadGrade_withoutJianyi.set_index(['index'],inplace=True)\n",
    "data_roadGrade_withoutJianyi['index']  = range(len(data_roadGrade_withoutJianyi))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# a = list([1,2,3])\n",
    "# a.append(a)\n",
    "# for name,group in data_gbRoadNo:\n",
    "#     print(name)\n",
    "# data_roadGrade_withoutJianyi.iloc[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 为每条数据按路号，添加三段道路的道路信息数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "info = {}\n",
    "roadColumns = ['事故多发点段','交通标志标线完善','其他交通安全设施不全','路侧防护设施类型',\\\n",
    "               '路口路段类型','路面状况','路面结构','交通信号方式（控制）',\\\n",
    "               '道路安全属性','道路安全隐患督办等级','道路物理隔离','道路类型','道路线型','长下坡路段']\n",
    "data_gbRoadNo = data_roadGrade_withoutJianyi.groupby(['路号'])\n",
    "\n",
    "roadInfo_all = list()\n",
    "\n",
    "for i in range(len(data_roadGrade_withoutJianyi)):\n",
    "    roadInfo_single = list()\n",
    "    roadInfo_single.append(i)\n",
    "    roadInfo_single.append(data_roadGrade_withoutJianyi.loc[i,'路号'])\n",
    "    \n",
    "    road_fir = list()\n",
    "    for c in roadColumns:\n",
    "        road_fir.append(data_roadGrade_withoutJianyi.loc[i,c])\n",
    "    roadInfo_single.append(road_fir)#添加第一条道路信息\n",
    "    \n",
    "    for name,group in data_gbRoadNo:\n",
    "        if len(roadInfo_single)==5:\n",
    "            break\n",
    "        if np.abs(roadInfo_single[1]-name)<=30 and np.abs(roadInfo_single[1]-name)>0:#避免与自身路号重复\n",
    "#             print(name)\n",
    "            road_next = list()\n",
    "            for rn_c in roadColumns:\n",
    "                 road_next.append( group[rn_c].value_counts().index[0] )\n",
    "            roadInfo_single.append(road_next)\n",
    "    while len(roadInfo_single)<5:\n",
    "        roadInfo_single.append(road_fir)\n",
    "    roadInfo_single.append(data_roadGrade_withoutJianyi.loc[i,'事故类型'])\n",
    "        \n",
    "    roadInfo_all.append(roadInfo_single)\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "45\n"
     ]
    }
   ],
   "source": [
    "dataForCNN = pd.DataFrame(columns=list(range(45)))\n",
    "for road_block in roadInfo_all:\n",
    "    instance = list()\n",
    "    for i in road_block:\n",
    "        if isinstance(i,list):\n",
    "            for d in i:\n",
    "                instance.append(d)\n",
    "        else:\n",
    "            instance.append(i)\n",
    "    instance = pd.Series(instance)\n",
    "    dataForCNN = dataForCNN.append(instance,ignore_index=True)\n",
    "print(len(instance))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>35</th>\n",
       "      <th>36</th>\n",
       "      <th>37</th>\n",
       "      <th>38</th>\n",
       "      <th>39</th>\n",
       "      <th>40</th>\n",
       "      <th>41</th>\n",
       "      <th>42</th>\n",
       "      <th>43</th>\n",
       "      <th>44</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>81509.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>否</td>\n",
       "      <td>否</td>\n",
       "      <td>绿化带</td>\n",
       "      <td>普通路段</td>\n",
       "      <td>路面完好</td>\n",
       "      <td>沥青</td>\n",
       "      <td>45</td>\n",
       "      <td>...</td>\n",
       "      <td>路面完好</td>\n",
       "      <td>沥青</td>\n",
       "      <td>45</td>\n",
       "      <td>正常路段</td>\n",
       "      <td>4.0</td>\n",
       "      <td>中心隔离</td>\n",
       "      <td>一般城市道路</td>\n",
       "      <td>平直</td>\n",
       "      <td>否</td>\n",
       "      <td>伤人事故</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.0</td>\n",
       "      <td>61022.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>否</td>\n",
       "      <td>否</td>\n",
       "      <td>混凝土护拦</td>\n",
       "      <td>高架路段</td>\n",
       "      <td>路面完好</td>\n",
       "      <td>沥青</td>\n",
       "      <td>45</td>\n",
       "      <td>...</td>\n",
       "      <td>路面完好</td>\n",
       "      <td>沥青</td>\n",
       "      <td>345</td>\n",
       "      <td>正常路段</td>\n",
       "      <td>4.0</td>\n",
       "      <td>机非隔离</td>\n",
       "      <td>一般城市道路</td>\n",
       "      <td>平直</td>\n",
       "      <td>否</td>\n",
       "      <td>伤人事故</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2.0</td>\n",
       "      <td>95999.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>否</td>\n",
       "      <td>否</td>\n",
       "      <td>无防护</td>\n",
       "      <td>三枝分叉口</td>\n",
       "      <td>路面完好</td>\n",
       "      <td>沥青</td>\n",
       "      <td>456</td>\n",
       "      <td>...</td>\n",
       "      <td>路面完好</td>\n",
       "      <td>沥青</td>\n",
       "      <td>456</td>\n",
       "      <td>正常路段</td>\n",
       "      <td>4.0</td>\n",
       "      <td>无隔离</td>\n",
       "      <td>城市快速路</td>\n",
       "      <td>平直</td>\n",
       "      <td>否</td>\n",
       "      <td>伤人事故</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3.0</td>\n",
       "      <td>50076.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>否</td>\n",
       "      <td>否</td>\n",
       "      <td>混凝土护拦</td>\n",
       "      <td>高架路段</td>\n",
       "      <td>路面完好</td>\n",
       "      <td>沥青</td>\n",
       "      <td>456</td>\n",
       "      <td>...</td>\n",
       "      <td>路面完好</td>\n",
       "      <td>沥青</td>\n",
       "      <td>456</td>\n",
       "      <td>正常路段</td>\n",
       "      <td>4.0</td>\n",
       "      <td>中心隔离</td>\n",
       "      <td>高速</td>\n",
       "      <td>平直</td>\n",
       "      <td>否</td>\n",
       "      <td>死亡事故</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4.0</td>\n",
       "      <td>94068.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>否</td>\n",
       "      <td>否</td>\n",
       "      <td>无防护</td>\n",
       "      <td>其他特殊路段</td>\n",
       "      <td>其他</td>\n",
       "      <td>水泥</td>\n",
       "      <td>无信号</td>\n",
       "      <td>...</td>\n",
       "      <td>其他</td>\n",
       "      <td>水泥</td>\n",
       "      <td>无信号</td>\n",
       "      <td>正常路段</td>\n",
       "      <td>4.0</td>\n",
       "      <td>无隔离</td>\n",
       "      <td>其他路</td>\n",
       "      <td>平直</td>\n",
       "      <td>否</td>\n",
       "      <td>伤人事故</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 45 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    0        1    2  3  4      5       6     7   8    9   ...     35  36   37  \\\n",
       "0  0.0  81509.0  2.0  否  否    绿化带    普通路段  路面完好  沥青   45  ...   路面完好  沥青   45   \n",
       "1  1.0  61022.0  2.0  否  否  混凝土护拦    高架路段  路面完好  沥青   45  ...   路面完好  沥青  345   \n",
       "2  2.0  95999.0  2.0  否  否    无防护   三枝分叉口  路面完好  沥青  456  ...   路面完好  沥青  456   \n",
       "3  3.0  50076.0  2.0  否  否  混凝土护拦    高架路段  路面完好  沥青  456  ...   路面完好  沥青  456   \n",
       "4  4.0  94068.0  2.0  否  否    无防护  其他特殊路段    其他  水泥  无信号  ...     其他  水泥  无信号   \n",
       "\n",
       "     38   39    40      41  42 43    44  \n",
       "0  正常路段  4.0  中心隔离  一般城市道路  平直  否  伤人事故  \n",
       "1  正常路段  4.0  机非隔离  一般城市道路  平直  否  伤人事故  \n",
       "2  正常路段  4.0   无隔离   城市快速路  平直  否  伤人事故  \n",
       "3  正常路段  4.0  中心隔离      高速  平直  否  死亡事故  \n",
       "4  正常路段  4.0   无隔离     其他路  平直  否  伤人事故  \n",
       "\n",
       "[5 rows x 45 columns]"
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataForCNN.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0: 0.0  1: 0.0  2: 0.0  3: 0.0  \n",
      "4: 0.0  5: 0.0  6: 0.0  7: 0.0  \n",
      "8: 0.0  9: 0.0  10: 0.0  11: 0.0  \n",
      "12: 0.0  13: 0.0  14: 0.0  15: 0.0  \n",
      "16: 0.0  17: 0.0  18: 0.0  19: 0.0  \n",
      "20: 0.0  21: 0.0  22: 0.0  23: 0.0  \n",
      "24: 0.0  25: 0.0  26: 0.0  27: 0.0  \n",
      "28: 0.0  29: 0.0  30: 0.0  31: 0.0  \n",
      "32: 0.0  33: 0.0  34: 0.0  35: 0.0  \n",
      "36: 0.0  37: 0.0  38: 0.0  39: 0.0  \n",
      "40: 0.0  41: 0.0  42: 0.0  43: 0.0  \n",
      "44: 0.0  774\n"
     ]
    }
   ],
   "source": [
    "nan_columns = {}\n",
    "length_data = len(dataForCNN)\n",
    "for i in range(len(dataForCNN.columns)): \n",
    "    odds = sum(dataForCNN[dataForCNN.columns[i]].isnull())/length_data\n",
    "    nan_columns[dataForCNN.columns[i]] = odds\n",
    "j = 0\n",
    "for i in nan_columns:\n",
    "    print(str(i)+': '+str(nan_columns[i]),end='  ')\n",
    "    j+=1\n",
    "    if j==4:\n",
    "        j=0\n",
    "        print()\n",
    "        \n",
    "print(len(dataForCNN))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "dataForCNN.to_excel('dataForCNN_17.11.14.xlsx')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 获取训练集和测试集"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dataForCNN = pd.read_excel('dataForCNN_17.11.14.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>...</th>\n",
       "      <th>34</th>\n",
       "      <th>35</th>\n",
       "      <th>36</th>\n",
       "      <th>37</th>\n",
       "      <th>38</th>\n",
       "      <th>39</th>\n",
       "      <th>40</th>\n",
       "      <th>41</th>\n",
       "      <th>42</th>\n",
       "      <th>43</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>否</td>\n",
       "      <td>否</td>\n",
       "      <td>绿化带</td>\n",
       "      <td>普通路段</td>\n",
       "      <td>路面完好</td>\n",
       "      <td>沥青</td>\n",
       "      <td>方式2</td>\n",
       "      <td>正常路段</td>\n",
       "      <td>...</td>\n",
       "      <td>普通路段</td>\n",
       "      <td>路面完好</td>\n",
       "      <td>沥青</td>\n",
       "      <td>方式2</td>\n",
       "      <td>正常路段</td>\n",
       "      <td>4</td>\n",
       "      <td>中心隔离</td>\n",
       "      <td>一般城市道路</td>\n",
       "      <td>平直</td>\n",
       "      <td>否</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>否</td>\n",
       "      <td>否</td>\n",
       "      <td>混凝土护拦</td>\n",
       "      <td>高架路段</td>\n",
       "      <td>路面完好</td>\n",
       "      <td>沥青</td>\n",
       "      <td>方式2</td>\n",
       "      <td>正常路段</td>\n",
       "      <td>...</td>\n",
       "      <td>普通路段</td>\n",
       "      <td>路面完好</td>\n",
       "      <td>沥青</td>\n",
       "      <td>方式1</td>\n",
       "      <td>正常路段</td>\n",
       "      <td>4</td>\n",
       "      <td>机非隔离</td>\n",
       "      <td>一般城市道路</td>\n",
       "      <td>平直</td>\n",
       "      <td>否</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>否</td>\n",
       "      <td>否</td>\n",
       "      <td>无防护</td>\n",
       "      <td>三枝分叉口</td>\n",
       "      <td>路面完好</td>\n",
       "      <td>沥青</td>\n",
       "      <td>方式3</td>\n",
       "      <td>正常路段</td>\n",
       "      <td>...</td>\n",
       "      <td>三枝分叉口</td>\n",
       "      <td>路面完好</td>\n",
       "      <td>沥青</td>\n",
       "      <td>方式3</td>\n",
       "      <td>正常路段</td>\n",
       "      <td>4</td>\n",
       "      <td>无隔离</td>\n",
       "      <td>城市快速路</td>\n",
       "      <td>平直</td>\n",
       "      <td>否</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>否</td>\n",
       "      <td>否</td>\n",
       "      <td>混凝土护拦</td>\n",
       "      <td>高架路段</td>\n",
       "      <td>路面完好</td>\n",
       "      <td>沥青</td>\n",
       "      <td>方式3</td>\n",
       "      <td>正常路段</td>\n",
       "      <td>...</td>\n",
       "      <td>高架路段</td>\n",
       "      <td>路面完好</td>\n",
       "      <td>沥青</td>\n",
       "      <td>方式3</td>\n",
       "      <td>正常路段</td>\n",
       "      <td>4</td>\n",
       "      <td>中心隔离</td>\n",
       "      <td>高速</td>\n",
       "      <td>平直</td>\n",
       "      <td>否</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>否</td>\n",
       "      <td>否</td>\n",
       "      <td>无防护</td>\n",
       "      <td>其他特殊路段</td>\n",
       "      <td>其他</td>\n",
       "      <td>水泥</td>\n",
       "      <td>无信号</td>\n",
       "      <td>正常路段</td>\n",
       "      <td>...</td>\n",
       "      <td>其他特殊路段</td>\n",
       "      <td>其他</td>\n",
       "      <td>水泥</td>\n",
       "      <td>无信号</td>\n",
       "      <td>正常路段</td>\n",
       "      <td>4</td>\n",
       "      <td>无隔离</td>\n",
       "      <td>其他路</td>\n",
       "      <td>平直</td>\n",
       "      <td>否</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 43 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   0   2  3  4      5       6     7   8    9     10 ...      34    35  36  \\\n",
       "0   0   2  否  否    绿化带    普通路段  路面完好  沥青  方式2  正常路段 ...    普通路段  路面完好  沥青   \n",
       "1   1   2  否  否  混凝土护拦    高架路段  路面完好  沥青  方式2  正常路段 ...    普通路段  路面完好  沥青   \n",
       "2   2   2  否  否    无防护   三枝分叉口  路面完好  沥青  方式3  正常路段 ...   三枝分叉口  路面完好  沥青   \n",
       "3   3   2  否  否  混凝土护拦    高架路段  路面完好  沥青  方式3  正常路段 ...    高架路段  路面完好  沥青   \n",
       "4   4   2  否  否    无防护  其他特殊路段    其他  水泥  无信号  正常路段 ...  其他特殊路段    其他  水泥   \n",
       "\n",
       "    37    38  39    40      41  42 43  \n",
       "0  方式2  正常路段   4  中心隔离  一般城市道路  平直  否  \n",
       "1  方式1  正常路段   4  机非隔离  一般城市道路  平直  否  \n",
       "2  方式3  正常路段   4   无隔离   城市快速路  平直  否  \n",
       "3  方式3  正常路段   4  中心隔离      高速  平直  否  \n",
       "4  无信号  正常路段   4   无隔离     其他路  平直  否  \n",
       "\n",
       "[5 rows x 43 columns]"
      ]
     },
     "execution_count": 189,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#test\n",
    "dataForCNN.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#训练集1\n",
    "dataForCNN = pd.read_excel('dataForCNN_17.11.14.xlsx')\n",
    "\n",
    "dataForCNN.loc[dataForCNN[9]==345,9]='方式1'\n",
    "dataForCNN.loc[dataForCNN[9]==45,9]='方式2'\n",
    "dataForCNN.loc[dataForCNN[9]==456,9]='方式3'\n",
    "dataForCNN.loc[dataForCNN[9]==3456,9]='方式4'\n",
    "dataForCNN.loc[dataForCNN[9]==16,9]='方式5'\n",
    "dataForCNN.loc[dataForCNN[9]==34,9]='方式6'\n",
    "dataForCNN.loc[dataForCNN[9]==56,9]='方式7'\n",
    "dataForCNN.loc[dataForCNN[9]==356,9]='方式8'\n",
    "\n",
    "dataForCNN.loc[dataForCNN[23]==345,23]='方式1'\n",
    "dataForCNN.loc[dataForCNN[23]==45,23]='方式2'\n",
    "dataForCNN.loc[dataForCNN[23]==456,23]='方式3'\n",
    "dataForCNN.loc[dataForCNN[23]==3456,23]='方式4'\n",
    "dataForCNN.loc[dataForCNN[23]==16,23]='方式5'\n",
    "dataForCNN.loc[dataForCNN[23]==34,23]='方式6'\n",
    "dataForCNN.loc[dataForCNN[23]==56,23]='方式7'\n",
    "dataForCNN.loc[dataForCNN[23]==356,23]='方式8'\n",
    "\n",
    "dataForCNN.loc[dataForCNN[37]==345,37]='方式1'\n",
    "dataForCNN.loc[dataForCNN[37]==45,37]='方式2'\n",
    "dataForCNN.loc[dataForCNN[37]==456,37]='方式3'\n",
    "dataForCNN.loc[dataForCNN[37]==3456,37]='方式4'\n",
    "dataForCNN.loc[dataForCNN[37]==16,37]='方式5'\n",
    "dataForCNN.loc[dataForCNN[37]==34,37]='方式6'\n",
    "dataForCNN.loc[dataForCNN[37]==56,37]='方式7'\n",
    "dataForCNN.loc[dataForCNN[37]==356,37]='方式8'\n",
    "\n",
    "# dataForCNN.drop([44],axis=1,inplace=True)#删除事故类型\n",
    "# dataForCNN.drop([1],axis=1,inplace=True)#删除路号\n",
    "\n",
    "dataForCNN_toNum = pd.DataFrame()\n",
    "for i in dataForCNN.columns:\n",
    "#     print(i)\n",
    "    dataForCNN_toNum[i] = preprocessing.LabelEncoder().fit_transform(dataForCNN[i])\n",
    "\n",
    "#训练集2\n",
    "data_roadGrade_withoutJianyi = pd.read_excel('data_roadGrade_withoutJianyi_17.11.15.xlsx')\n",
    "#交通信号方式（控制）\n",
    "# sns.countplot(data_roadGrade_withoutJianyi['交通信号方式（控制）'])\n",
    "data_roadGrade_withoutJianyi.loc[data_roadGrade_withoutJianyi['交通信号方式（控制）']==345,'交通信号方式（控制）']='方式1'\n",
    "data_roadGrade_withoutJianyi.loc[data_roadGrade_withoutJianyi['交通信号方式（控制）']==45,'交通信号方式（控制）']='方式2'\n",
    "data_roadGrade_withoutJianyi.loc[data_roadGrade_withoutJianyi['交通信号方式（控制）']==456,'交通信号方式（控制）']='方式3'\n",
    "data_roadGrade_withoutJianyi.loc[data_roadGrade_withoutJianyi['交通信号方式（控制）']==3456,'交通信号方式（控制）']='方式4'\n",
    "data_roadGrade_withoutJianyi.loc[data_roadGrade_withoutJianyi['交通信号方式（控制）']==16,'交通信号方式（控制）']='方式5'\n",
    "data_roadGrade_withoutJianyi.loc[data_roadGrade_withoutJianyi['交通信号方式（控制）']==34,'交通信号方式（控制）']='方式6'\n",
    "data_roadGrade_withoutJianyi.loc[data_roadGrade_withoutJianyi['交通信号方式（控制）']==56,'交通信号方式（控制）']='方式7'\n",
    "data_roadGrade_withoutJianyi.loc[data_roadGrade_withoutJianyi['交通信号方式（控制）']==356,'交通信号方式（控制）']='方式8'\n",
    "\n",
    "# sns.countplot(data_roadGrade_withoutJianyi['交通信号方式（控制）'])\n",
    "#删除星期\n",
    "data_roadGrade_withoutJianyi.drop(['星期'],axis=1,inplace=True)\n",
    "\n",
    "#转换为数字\n",
    "data_roadGrade_withoutJianyi_toNum = pd.DataFrame()\n",
    "data_roadGrade_withoutJianyi_toNum['路宽'] = data_roadGrade_withoutJianyi['路宽']\n",
    "for i in [x for x in data_roadGrade_withoutJianyi.columns if x not in ['路宽']]:\n",
    "        data_roadGrade_withoutJianyi_toNum[i] = \\\n",
    "                preprocessing.LabelEncoder().fit_transform(data_roadGrade_withoutJianyi[i])\n",
    "data_roadGrade_withoutJianyi_toNum['index'] = range(len(data_roadGrade_withoutJianyi_toNum))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# data_roadGrade_withoutJianyi_toNum.head(10)\n",
    "# dataForCNN_toNum.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dataForCNNAndXG_toNum = pd.merge(left=dataForCNN_toNum,right=data_roadGrade_withoutJianyi_toNum,\\\n",
    "                           left_on=[0],right_on=['index'],how='inner')\n",
    "dataForCNNAndXG_toNum.drop(['index'],axis=1,inplace=True)#删除编号，不删除‘0’列，后面要用"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "43\n",
      "33\n",
      "75\n"
     ]
    }
   ],
   "source": [
    "print(len(dataForCNN_toNum.columns))\n",
    "print(len(data_roadGrade_withoutJianyi_toNum.columns))\n",
    "#其中2-43为三段道路信息，需要代入CNN中\n",
    "print(len(dataForCNNAndXG_toNum.columns))   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "658\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\ProgramFiles\\Anaconda3\\lib\\site-packages\\ipykernel\\__main__.py:9: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "D:\\ProgramFiles\\Anaconda3\\lib\\site-packages\\ipykernel\\__main__.py:11: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n"
     ]
    }
   ],
   "source": [
    "#test\n",
    "\n",
    "# #生成训练集和测试集\n",
    "# dataForCNN_test = dataForCNN.sample(frac=0.15,replace=False)\n",
    "# # #获取训练集\n",
    "# index = ~dataForCNN[0].isin(dataForCNN_test[0])\n",
    "# print(sum(index==True))\n",
    "# dataForCNN_train = dataForCNN[index]\n",
    "\n",
    "# # #转换为数字\n",
    "# dataForCNN_train.drop([0],axis=1,inplace=True)#删除编号\n",
    "# dataForCNN_test.drop([0],axis=1,inplace=True)#删除编号\n",
    "# dataForCNN_train.drop([1],axis=1,inplace=True)#删除路号\n",
    "# dataForCNN_test.drop([1],axis=1,inplace=True)#删除路号\n",
    "# columnsToNum = list(dataForCNN.columns)\n",
    "\n",
    "# set_toNum = pd.DataFrame()\n",
    "# for i in columnsToNum:\n",
    "# #     print(i)\n",
    "#     set_toNum[i] = preprocessing.LabelEncoder().fit_transform(dataForCNN[i])\n",
    "\n",
    "# columnsToNum = list(dataForCNN_train.columns)\n",
    "# trainSet_toNum = pd.DataFrame()\n",
    "# for i in columnsToNum:\n",
    "#     trainSet_toNum[i] = preprocessing.LabelEncoder().fit_transform(dataForCNN_train[i])\n",
    "\n",
    "# # columnsToNum = list(data_attach_notnull_test.columns)\n",
    "# testSet_toNum = pd.DataFrame()\n",
    "# for i in columnsToNum:\n",
    "#     testSet_toNum[i] = preprocessing.LabelEncoder().fit_transform(dataForCNN_test[i])\n",
    "\n",
    "# del dataForCNN_train,dataForCNN_test,dataForCNN\n",
    "\n",
    "# #统一训练集、测试集格式\n",
    "# train_features = trainSet_toNum.drop([44],axis=1).columns\n",
    "\n",
    "# x_all =np.array(set_toNum.drop([44],axis=1)) \n",
    "# y_all = np.array(set_toNum[44])\n",
    "# y = np.zeros((len(y_all),len(set_toNum.groupby(44)) ))\n",
    "# for i in range(len(y_all)):\n",
    "#     y[i][y_all[i]] = 1\n",
    "# y_all = np.mat(y)\n",
    "# x_all = np.mat(x_all)\n",
    "# # y_all = np.mat(y_all)\n",
    "\n",
    "# x_train =np.array(trainSet_toNum.drop([44],axis=1)) \n",
    "# y_train = np.array(trainSet_toNum[44])\n",
    "# y = np.zeros((len(y_train),len(trainSet_toNum.groupby(44)) ))\n",
    "# for i in range(len(y_train)):\n",
    "#     y[i][y_train[i]] = 1\n",
    "# y_train = np.mat(y)\n",
    "# x_train = np.mat(x_train)\n",
    "# # y_train = np.mat(y_train)\n",
    "\n",
    "\n",
    "# x_test =np.array(testSet_toNum.drop([44],axis=1)) \n",
    "# y_test = np.array(testSet_toNum[44])\n",
    "# y = np.zeros((len(y_test),len(testSet_toNum.groupby(44)) ))\n",
    "# for i in range(len(y_test)):\n",
    "#     y[i][y_test[i]] = 1\n",
    "# y_test = np.mat(y)\n",
    "# x_test = np.mat(x_test)\n",
    "# # y_test = np.mat(y_test)\n",
    "\n",
    "\n",
    "# del y,trainSet_toNum,testSet_toNum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0      0\n",
       "1      0\n",
       "2      0\n",
       "3      1\n",
       "4      0\n",
       "5      0\n",
       "6      0\n",
       "7      2\n",
       "8      1\n",
       "9      0\n",
       "10     1\n",
       "11     0\n",
       "12     1\n",
       "13     0\n",
       "14     1\n",
       "15     0\n",
       "16     0\n",
       "17     0\n",
       "18     2\n",
       "19     0\n",
       "20     1\n",
       "21     0\n",
       "22     0\n",
       "23     1\n",
       "24     0\n",
       "25     1\n",
       "26     2\n",
       "27     1\n",
       "28     0\n",
       "29     1\n",
       "      ..\n",
       "744    1\n",
       "745    0\n",
       "746    1\n",
       "747    0\n",
       "748    1\n",
       "749    2\n",
       "750    1\n",
       "751    0\n",
       "752    1\n",
       "753    0\n",
       "754    0\n",
       "755    0\n",
       "756    0\n",
       "757    1\n",
       "758    0\n",
       "759    0\n",
       "760    0\n",
       "761    0\n",
       "762    0\n",
       "763    1\n",
       "764    1\n",
       "765    2\n",
       "766    2\n",
       "767    1\n",
       "768    1\n",
       "769    0\n",
       "770    1\n",
       "771    2\n",
       "772    0\n",
       "773    1\n",
       "Name: 事故类型, dtype: int64"
      ]
     },
     "execution_count": 204,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataForCNNAndXG_toNum['事故类型']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#生成训练集和测试集\n",
    "dataForCNNAndXG_test = dataForCNNAndXG_toNum.sample(frac=0.1,replace=False)\n",
    "# #获取训练集\n",
    "index = ~dataForCNNAndXG_toNum[0].isin(dataForCNNAndXG_test[0])\n",
    "dataForCNNAndXG_train = dataForCNNAndXG_toNum[index]\n",
    "\n",
    "#统一训练集、测试集格式\n",
    "train_features = [x for x in dataForCNNAndXG_toNum.columns if x not in ['事故类型',0]]\n",
    "\n",
    "x_all =np.array(dataForCNNAndXG_toNum.drop(['事故类型',0],axis=1)) \n",
    "y_all = np.array(dataForCNNAndXG_toNum['事故类型'])\n",
    "y = np.zeros((len(y_all),len(dataForCNNAndXG_toNum.groupby('事故类型')) ))\n",
    "for i in range(len(y_all)):\n",
    "    y[i][y_all[i]] = 1\n",
    "y_all = np.mat(y)\n",
    "x_all = np.mat(x_all)\n",
    "\n",
    "x_train =np.array(dataForCNNAndXG_train.drop(['事故类型',0],axis=1)) \n",
    "y_train = np.array(dataForCNNAndXG_train['事故类型'])\n",
    "y = np.zeros((len(y_train),len(dataForCNNAndXG_train.groupby('事故类型')) ))\n",
    "for i in range(len(y_train)):\n",
    "    y[i][y_train[i]] = 1\n",
    "y_train = np.mat(y)\n",
    "x_train = np.mat(x_train)\n",
    "\n",
    "\n",
    "x_test =np.array(dataForCNNAndXG_test.drop(['事故类型',0],axis=1)) \n",
    "y_test = np.array(dataForCNNAndXG_test['事故类型'])\n",
    "y = np.zeros((len(y_test),len(dataForCNNAndXG_test.groupby('事故类型')) ))\n",
    "for i in range(len(y_test)):\n",
    "    y[i][y_test[i]] = 1\n",
    "y_test = np.mat(y)\n",
    "x_test = np.mat(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "43\n",
      "33\n",
      "75\n",
      "(697, 73)\n",
      "(697, 3)\n"
     ]
    }
   ],
   "source": [
    "#包括编号,最后训练特征为42\n",
    "print(len(dataForCNN_toNum.columns))\n",
    "#33，包括index和事故类型,最后训练特征为31\n",
    "print(len(data_roadGrade_withoutJianyi_toNum.columns))\n",
    "#其中2-43为三段道路信息，需要代入CNN中\n",
    "print(len(dataForCNNAndXG_toNum.columns))   \n",
    "\n",
    "#前面42个特征代入cnn，后面31个特征加入xgboost\n",
    "print(x_train.shape)\n",
    "print(y_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(77, 42)"
      ]
     },
     "execution_count": 198,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_test[:,:42].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# data_roadGrade_withoutJianyi_toNum.columns\n",
    "\n",
    "# data_roadGrade_withoutJianyi_toNum['index'] = range(len(data_roadGrade_withoutJianyi_toNum))\n",
    "# data_roadGrade_withoutJianyi_toNum.set_index(['index'],inplace=True)\n",
    "# data_roadGrade_withoutJianyi_toNum.drop(['路号','事故地点','公里数','所辖乡镇'],axis=1,inplace=True)\n",
    "\n",
    "# data_roadGrade_withoutJianyi_toNum['路宽']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 训练CNN模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# View more python tutorial on my Youtube and Youku channel!!!\n",
    "\n",
    "# Youtube video tutorial: https://www.youtube.com/channel/UCdyjiB5H8Pu7aDTNVXTTpcg\n",
    "# Youku video tutorial: http://i.youku.com/pythontutorial\n",
    "\n",
    "\"\"\"\n",
    "Please note, this code is only for python 3+. If you are using python 2+, please modify the code accordingly.\n",
    "\"\"\"\n",
    "from __future__ import print_function\n",
    "import tensorflow as tf\n",
    "from tensorflow.examples.tutorials.mnist import input_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def compute_accuracy(v_xs, v_ys):\n",
    "    global prediction\n",
    "    y_pre = sess.run(prediction, feed_dict={xs: v_xs, keep_prob: 1})\n",
    "    correct_prediction = tf.equal(tf.argmax(y_pre,1), tf.argmax(v_ys,1))\n",
    "    accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n",
    "    result = sess.run(accuracy, feed_dict={xs: v_xs, ys: v_ys, keep_prob: 1})\n",
    "    return result\n",
    "\n",
    "def weight_variable(shape):\n",
    "    initial = tf.truncated_normal(shape, stddev=0.1)\n",
    "    return tf.Variable(initial)\n",
    "\n",
    "def bias_variable(shape):\n",
    "    initial = tf.constant(0.1, shape=shape)\n",
    "    return tf.Variable(initial)\n",
    "\n",
    "def conv2d(x, W):\n",
    "    # stride [1, x_movement, y_movement, 1]\n",
    "    # Must have strides[0] = strides[3] = 1\n",
    "    return tf.nn.conv2d(x, W, strides=[1, 1, 1, 1], padding='SAME')\n",
    "\n",
    "def max_pool_2x2(x):\n",
    "    # stride [1, x_movement, y_movement, 1]\n",
    "    return tf.nn.max_pool(x, ksize=[1,2,2,1], strides=[1,2,2,1], padding='SAME')\n",
    "\n",
    "\n",
    "# define placeholder for inputs to network\n",
    "xs = tf.placeholder(tf.float32, [None, 42])   # 14x3\n",
    "ys = tf.placeholder(tf.float32, [None, 3])\n",
    "keep_prob = tf.placeholder(tf.float32)\n",
    "x_image = tf.reshape(xs, [-1, 14, 3, 1])\n",
    "# print(x_image.shape)  # [n_samples, 28,28,1]\n",
    "\n",
    "## conv1 layer ##\n",
    "W_conv1 = weight_variable([5,5, 1,42]) # patch 5x5, in size 1, out size 42\n",
    "b_conv1 = bias_variable([42])\n",
    "h_conv1 = tf.nn.relu(conv2d(x_image, W_conv1) + b_conv1) # output size 14x3x42\n",
    "h_pool1 = max_pool_2x2(h_conv1)      # output size 7x2x42\n",
    "\n",
    "## conv2 layer ##\n",
    "W_conv2 = weight_variable([5,5, 42, 84]) # patch 5x5, in size 42, out size 84\n",
    "b_conv2 = bias_variable([84])\n",
    "h_conv2 = tf.nn.relu(conv2d(h_pool1, W_conv2) + b_conv2) # output size 7x2x84\n",
    "h_pool2 = max_pool_2x2(h_conv2)                                         # output size 4x1x84\n",
    "\n",
    "\n",
    "## fc1 layer ##\n",
    "W_fc1 = weight_variable([4*1*84, 336])   #注意此处特征值数量是否出现问题\n",
    "b_fc1 = bias_variable([336])\n",
    "h_pool2_flat = tf.reshape(h_pool2, [-1, 336])\n",
    "h_fc1 = tf.nn.relu(tf.matmul(h_pool2_flat, W_fc1) + b_fc1)\n",
    "h_fc1_drop = tf.nn.dropout(h_fc1, keep_prob)\n",
    "\n",
    "## fc2 layer ##\n",
    "W_fc2 = weight_variable([336, 3])\n",
    "b_fc2 = bias_variable([3])\n",
    "prediction = tf.nn.softmax(tf.matmul(h_fc1_drop, W_fc2) + b_fc2)\n",
    "\n",
    "# the error between prediction and real data\n",
    "cross_entropy = tf.reduce_mean(-tf.reduce_sum(ys * tf.log(prediction),\n",
    "                                              reduction_indices=[1]))       # loss\n",
    "train_step = tf.train.AdamOptimizer(1e-4).minimize(cross_entropy)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.103896\n",
      "0.61039\n",
      "0.61039\n",
      "0.636364\n",
      "0.636364\n",
      "0.636364\n",
      "0.636364\n",
      "0.61039\n",
      "0.597403\n",
      "0.636364\n",
      "0.584416\n",
      "0.649351\n",
      "0.623377\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-201-ea25c8676c2c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0mcomAuc\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1000\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m     \u001b[0msess\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain_step\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m{\u001b[0m\u001b[0mxs\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mx_train\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;36m42\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mys\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkeep_prob\u001b[0m\u001b[1;33m:\u001b[0m \u001b[1;36m0.5\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mi\u001b[0m \u001b[1;33m%\u001b[0m \u001b[1;36m50\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mcomAuc\u001b[0m \u001b[1;33m<\u001b[0m \u001b[0mcompute_accuracy\u001b[0m\u001b[1;33m(\u001b[0m \u001b[0mx_test\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;36m42\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mD:\\ProgramFiles\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    787\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    788\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 789\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    790\u001b[0m       \u001b[1;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    791\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mD:\\ProgramFiles\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    995\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    996\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m--> 997\u001b[0;31m                              feed_dict_string, options, run_metadata)\n\u001b[0m\u001b[1;32m    998\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    999\u001b[0m       \u001b[0mresults\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mD:\\ProgramFiles\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1130\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m   1131\u001b[0m       return self._do_call(_run_fn, self._session, feed_dict, fetch_list,\n\u001b[0;32m-> 1132\u001b[0;31m                            target_list, options, run_metadata)\n\u001b[0m\u001b[1;32m   1133\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m   1134\u001b[0m       return self._do_call(_prun_fn, self._session, handle, feed_dict,\n",
      "\u001b[0;32mD:\\ProgramFiles\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1137\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m   1138\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1139\u001b[0;31m       \u001b[1;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1140\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m   1141\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mD:\\ProgramFiles\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(session, feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1119\u001b[0m         return tf_session.TF_Run(session, options,\n\u001b[1;32m   1120\u001b[0m                                  \u001b[0mfeed_dict\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1121\u001b[0;31m                                  status, run_metadata)\n\u001b[0m\u001b[1;32m   1122\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m   1123\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msession\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "sess = tf.Session()\n",
    "# important step\n",
    "# tf.initialize_all_variables() no long valid from\n",
    "# 2017-03-02 if using tensorflow >= 0.12\n",
    "if int((tf.__version__).split('.')[1]) < 12 and int((tf.__version__).split('.')[0]) < 1:\n",
    "    init = tf.initialize_all_variables()\n",
    "else:\n",
    "    init = tf.global_variables_initializer()\n",
    "sess.run(init)\n",
    "comAuc = 0\n",
    "for i in range(1000):\n",
    "    sess.run(train_step, feed_dict={xs: x_train[:,:42], ys: y_train, keep_prob: 0.5})\n",
    "    if i % 50 == 0:\n",
    "        if comAuc < compute_accuracy( x_test[:,:42], y_test):\n",
    "            comAuc = compute_accuracy( x_test[:,:42], y_test)\n",
    "            feaFromCNN = sess.run(\n",
    "                    tf.nn.max_pool(tf.nn.relu(tf.nn.conv2d(\n",
    "                    tf.nn.max_pool(tf.nn.relu(\\\n",
    "                        tf.nn.conv2d(tf.reshape(tf.cast(x_train[:,:42],tf.float32),[-1, 14, 3, 1]), W_conv1,\\\n",
    "                        strides=[1, 1, 1, 1], padding='SAME'  )+ b_conv1),\\\n",
    "                        ksize=[1,2,2,1], strides=[1,2,2,1], padding='SAME'),W_conv2,\\\n",
    "                        strides=[1, 1, 1, 1], padding='SAME'  )+ b_conv2),\\\n",
    "                        ksize=[1,2,2,1], strides=[1,2,2,1], padding='SAME'))\n",
    "        print(compute_accuracy( x_test[:,:42], y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "697"
      ]
     },
     "execution_count": 202,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#需要反向传递，暂时不知如何搞定\n",
    "#加入xgboost\n",
    "target = '事故类型'\n",
    "feaFromCNN = np.reshape(feaFromCNN,[feaFromCNN.shape[0],336])\n",
    "feaFromCNN = pd.DataFrame(feaFromCNN)\n",
    "feaFromCNN['index'] = range(len(feaFromCNN))\n",
    "feaFromOri = pd.DataFrame(x_test[:,42:])\n",
    "feaFromOri['index'] = range(len(feaFromOri))\n",
    "feaFromOri = pd.merge(left=feaFromCNN,right=feaFromOri,left_on=['index'],right_on=['index'])\n",
    "feaFromOri.drop(['index'],axis=1,inplace=True)\n",
    "\n",
    "def modelfit(alg, dtrain, dLabel,useTrainCV=True, cv_folds=5, early_stopping_rounds=50):  \n",
    "    if useTrainCV:\n",
    "        xgb_param = alg.get_xgb_params()\n",
    "        xgb_param['num_class'] = 3\n",
    "        xgtrain = xgb.DMatrix(dtrain.values, label=dLabel.values)\n",
    "        cvresult = xgb.cv(xgb_param, xgtrain, num_boost_round=alg.get_params()['n_estimators'], nfold=cv_folds,\n",
    "            metrics='merror', early_stopping_rounds=early_stopping_rounds)#, show_progress=False，多分类metrics使用merror\n",
    "        alg.set_params(n_estimators=cvresult.shape[0])\n",
    "    \n",
    "    #Fit the algorithm on the data\n",
    "    alg.fit(dtrain,dLabel,eval_metric='merror')    \n",
    "    #Predict training set:\n",
    "    dtrain_predictions = alg.predict(dtrain)\n",
    "    dtrain_predprob = alg.predict_proba(dtrain)[:,1]\n",
    "        \n",
    "\n",
    "\n",
    "\n",
    "    print (\"\\nModel Report\")\n",
    "    print (\"Accuracy : %.4g\" % metrics.accuracy_score(dLabel.values, dtrain_predictions))\n",
    "#     print (\"AUC Score (Train): %f\" % metrics.roc_auc_score(dtrain[target], dtrain_predprob))\n",
    "\n",
    "    cvresult = pd.DataFrame(cvresult)\n",
    "    print(\"Accuracy : %.4g\" % (1-cvresult.iloc[-1][0]))\n",
    "    print('test-auc-mean and test-auc-std and train-auc-mean and train-auc-std:')\n",
    "    print(cvresult.iloc[-1][:])#\n",
    "                    \n",
    "    feat_imp = pd.Series(alg.booster().get_fscore()).sort_values(ascending=False)\n",
    "    feat_imp.plot(kind='bar', title='Feature Importances')\n",
    "    plt.ylabel('Feature Importance Score')\n",
    "\n",
    "    return alg\n",
    "    \n",
    "xgb1 = XGBClassifier(\n",
    "    learning_rate =0.1,\n",
    "    n_estimators=1000,\n",
    "    max_depth=4,\n",
    "    min_child_weight=0,\n",
    "    gamma=0,\n",
    "    subsample=0.6,\n",
    "    colsample_bytree=0.7,\n",
    "    #  reg_alpha=0.005,\n",
    "    objective= 'multi:softmax',\n",
    "    nthread=4,\n",
    "    scale_pos_weight=1,\n",
    "    seed=27)\n",
    "alg,accuracy = modelfit(xgb1, feaFromOri, y_tr)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "    a = sess.run(\n",
    "        tf.nn.max_pool(tf.nn.relu(tf.nn.conv2d(\n",
    "        tf.nn.max_pool(tf.nn.relu(\\\n",
    "            tf.nn.conv2d(tf.reshape(tf.cast(x_train[:,:42],tf.float32),[-1, 14, 3, 1]), W_conv1,\\\n",
    "            strides=[1, 1, 1, 1], padding='SAME'  )+ b_conv1),\\\n",
    "            ksize=[1,2,2,1], strides=[1,2,2,1], padding='SAME'),W_conv2,\\\n",
    "            strides=[1, 1, 1, 1], padding='SAME'  )+ b_conv2),\\\n",
    "            ksize=[1,2,2,1], strides=[1,2,2,1], padding='SAME'))\n",
    "    a = np.reshape(a,[697,336])\n",
    "    a = pd.DataFrame(a)\n",
    "    a['index'] = range(len(a))\n",
    "    b = pd.DataFrame(x_test[:,42:])\n",
    "    b['index'] = range(len(b))\n",
    "    b = pd.merge(left=a,right=b,left_on=['index'],right_on=['index'])\n",
    "    b.drop(['index'],axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
